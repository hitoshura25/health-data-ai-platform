# Default values for observability stack
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Global settings
global:
  namespace: health-observability
  clusterName: health-platform-dev
  environment: development
  storageClass: standard

# Jaeger - Distributed Tracing
jaeger:
  enabled: true
  image:
    repository: jaegertracing/all-in-one
    tag: "1.52"
    pullPolicy: IfNotPresent

  replicaCount: 1

  resources:
    requests:
      cpu: 200m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 1Gi

  persistence:
    enabled: true
    storageClass: standard
    size: 5Gi

  service:
    type: ClusterIP
    ports:
      # Jaeger UI
      query: 16686
      # OTLP gRPC
      otlpGrpc: 4317
      # OTLP HTTP
      otlpHttp: 4318
      # Jaeger thrift
      jaegerThrift: 14268
      # Zipkin
      zipkin: 9411

  ingress:
    enabled: false
    className: nginx
    annotations:
      cert-manager.io/cluster-issuer: letsencrypt-staging
    host: jaeger.example.com
    tls:
      enabled: false
      secretName: jaeger-tls

  env:
    COLLECTOR_OTLP_ENABLED: "true"
    SPAN_STORAGE_TYPE: "badger"
    BADGER_EPHEMERAL: "false"
    BADGER_DIRECTORY_VALUE: "/badger/data"
    BADGER_DIRECTORY_KEY: "/badger/key"

# kube-prometheus-stack - Prometheus + Grafana + AlertManager
kube-prometheus-stack:
  enabled: true

  # Prometheus configuration
  prometheus:
    enabled: true

    prometheusSpec:
      # Resource limits
      resources:
        requests:
          cpu: 500m
          memory: 2Gi
        limits:
          cpu: 1000m
          memory: 4Gi

      # Storage configuration
      retention: 30d
      retentionSize: "18GB"
      storageSpec:
        volumeClaimTemplate:
          spec:
            storageClassName: standard
            accessModes: ["ReadWriteOnce"]
            resources:
              requests:
                storage: 20Gi

      # Service discovery
      serviceMonitorSelectorNilUsesHelmValues: false
      podMonitorSelectorNilUsesHelmValues: false
      ruleSelectorNilUsesHelmValues: false

      # External labels
      externalLabels:
        cluster: health-platform-dev
        environment: development

      # Scrape interval
      scrapeInterval: 15s
      evaluationInterval: 15s

  # Grafana configuration
  grafana:
    enabled: true

    adminPassword: "changeme123"

    persistence:
      enabled: true
      storageClassName: standard
      size: 5Gi

    resources:
      requests:
        cpu: 200m
        memory: 512Mi
      limits:
        cpu: 500m
        memory: 1Gi

    ingress:
      enabled: false
      ingressClassName: nginx
      annotations:
        cert-manager.io/cluster-issuer: letsencrypt-staging
      hosts:
        - grafana.example.com
      tls:
        - secretName: grafana-tls
          hosts:
            - grafana.example.com

    # Datasources
    datasources:
      datasources.yaml:
        apiVersion: 1
        datasources:
        - name: Prometheus
          type: prometheus
          url: http://{{ .Release.Name }}-kube-prometheus-prometheus:9090
          access: proxy
          isDefault: true
          editable: true

        - name: Loki
          type: loki
          url: http://{{ .Release.Name }}-loki:3100
          access: proxy
          editable: true

        - name: Jaeger
          type: jaeger
          url: http://jaeger-query:16686
          access: proxy
          editable: true

    # Dashboard providers
    dashboardProviders:
      dashboardproviders.yaml:
        apiVersion: 1
        providers:
        - name: 'default'
          orgId: 1
          folder: ''
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/default

        - name: 'health-platform'
          orgId: 1
          folder: 'Health Platform'
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/health-platform

    # Pre-configured dashboards from Grafana.com
    dashboards:
      default:
        kubernetes-cluster:
          gnetId: 7249
          revision: 1
          datasource: Prometheus

        kubernetes-pods:
          gnetId: 6417
          revision: 1
          datasource: Prometheus

        node-exporter:
          gnetId: 1860
          revision: 31
          datasource: Prometheus

    # Additional dashboard ConfigMaps will be created in templates/dashboards/

  # AlertManager configuration
  alertmanager:
    enabled: true

    alertmanagerSpec:
      resources:
        requests:
          cpu: 100m
          memory: 128Mi
        limits:
          cpu: 200m
          memory: 256Mi

      storage:
        volumeClaimTemplate:
          spec:
            storageClassName: standard
            accessModes: ["ReadWriteOnce"]
            resources:
              requests:
                storage: 5Gi

    config:
      global:
        resolve_timeout: 5m

      route:
        group_by: ['alertname', 'cluster', 'service', 'namespace']
        group_wait: 10s
        group_interval: 10s
        repeat_interval: 12h
        receiver: 'default'
        routes:
        - match:
            severity: critical
          receiver: critical
          continue: true
        - match:
            severity: warning
          receiver: warning

      receivers:
      - name: 'default'
        webhook_configs:
        - url: 'http://localhost:5001'
          send_resolved: true

      - name: 'critical'
        # Configure Slack, PagerDuty, email, etc. in production
        webhook_configs:
        - url: 'http://localhost:5001'
          send_resolved: true

      - name: 'warning'
        webhook_configs:
        - url: 'http://localhost:5001'
          send_resolved: true

  # Prometheus Operator
  prometheusOperator:
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      limits:
        cpu: 200m
        memory: 256Mi

  # Node Exporter
  prometheus-node-exporter:
    enabled: true
    resources:
      requests:
        cpu: 50m
        memory: 64Mi
      limits:
        cpu: 100m
        memory: 128Mi

  # Kube State Metrics
  kube-state-metrics:
    enabled: true
    resources:
      requests:
        cpu: 50m
        memory: 64Mi
      limits:
        cpu: 100m
        memory: 128Mi

# Loki - Log Aggregation
loki:
  enabled: true

  loki:
    auth_enabled: false

    storage:
      type: filesystem

    commonConfig:
      replication_factor: 1

    schemaConfig:
      configs:
      - from: 2024-01-01
        store: tsdb
        object_store: filesystem
        schema: v13
        index:
          prefix: index_
          period: 24h

    limits_config:
      retention_period: 168h  # 7 days
      max_query_series: 10000
      max_query_lookback: 168h

    compactor:
      retention_enabled: true
      retention_delete_delay: 2h

  deploymentMode: SingleBinary

  singleBinary:
    replicas: 1

    resources:
      requests:
        cpu: 200m
        memory: 512Mi
      limits:
        cpu: 400m
        memory: 1Gi

    persistence:
      enabled: true
      storageClass: standard
      size: 5Gi

  # Disable components we don't need
  backend:
    replicas: 0
  read:
    replicas: 0
  write:
    replicas: 0

  # Gateway
  gateway:
    enabled: false

  # Monitoring
  monitoring:
    selfMonitoring:
      enabled: false
      grafanaAgent:
        installOperator: false

# Promtail - Log Shipper
promtail:
  enabled: true

  config:
    clients:
      - url: http://{{ .Release.Name }}-loki:3100/loki/api/v1/push

    snippets:
      pipelineStages:
        # Parse container logs
        - cri: {}

        # Parse JSON logs
        - json:
            expressions:
              level: level
              msg: message
              trace_id: trace_id
              service: service

        # Add labels
        - labels:
            level:
            service:

        # Timestamp extraction
        - timestamp:
            source: timestamp
            format: RFC3339Nano

  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 200m
      memory: 256Mi

  # DaemonSet configuration
  daemonset:
    enabled: true

# ServiceMonitor configurations for Health Platform services
serviceMonitors:
  # Enable ServiceMonitor creation
  enabled: true

  # Health API Service
  healthApi:
    enabled: true
    namespace: health-api
    selector:
      matchLabels:
        app: health-api
    endpoints:
    - port: metrics
      path: /metrics
      interval: 15s

  # WebAuthn Service
  webauthn:
    enabled: true
    namespace: health-auth
    selector:
      matchLabels:
        app: webauthn-server
    endpoints:
    - port: metrics
      path: /metrics
      interval: 15s

  # ETL Narrative Engine
  etlEngine:
    enabled: true
    namespace: health-etl
    selector:
      matchLabels:
        app: etl-narrative-engine
    endpoints:
    - port: metrics
      path: /metrics
      interval: 15s

  # PostgreSQL (using postgres-exporter)
  postgresql:
    enabled: true
    namespace: health-data
    selector:
      matchLabels:
        app: postgres-exporter
    endpoints:
    - port: metrics
      path: /metrics
      interval: 30s

  # Redis (using redis-exporter)
  redis:
    enabled: true
    namespace: health-data
    selector:
      matchLabels:
        app: redis-exporter
    endpoints:
    - port: metrics
      path: /metrics
      interval: 30s

  # MinIO
  minio:
    enabled: true
    namespace: health-data
    selector:
      matchLabels:
        app: minio
    endpoints:
    - port: metrics
      path: /minio/v2/metrics/cluster
      interval: 30s

  # RabbitMQ
  rabbitmq:
    enabled: true
    namespace: health-data
    selector:
      matchLabels:
        app: rabbitmq
    endpoints:
    - port: prometheus
      path: /metrics
      interval: 30s

# Custom Grafana Dashboards
dashboards:
  # Health Platform Application Dashboard
  healthPlatform:
    enabled: true

  # Infrastructure Dashboard
  infrastructure:
    enabled: true

  # Cost Monitoring Dashboard
  costMonitoring:
    enabled: true

  # Security Dashboard
  security:
    enabled: true
