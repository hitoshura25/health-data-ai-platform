name: Schema Validation

on:
  push:
    branches: [main]
    paths:
      - 'shared/schemas/**'
      - 'shared/types/**'
      - 'shared/validation/**'
      - '.github/workflows/schema-validation.yml'
  pull_request:
    branches: [main]
    paths:
      - 'shared/schemas/**'
      - 'shared/types/**'
      - 'shared/validation/**'

jobs:
  validate-schemas:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install avro-python3 jsonschema pytest pytest-cov

    - name: Validate Avro schemas
      run: |
        cd shared/schemas

        # Function to validate Avro schema
        validate_avro_schema() {
            local schema_file=$1
            echo "Validating $schema_file..."

            python3 -c "
        import avro.schema
        import json
        import sys

        try:
            with open('$schema_file', 'r') as f:
                schema_dict = json.load(f)

            # Parse as Avro schema
            schema = avro.schema.parse(json.dumps(schema_dict))
            print('✅ Valid Avro schema: $schema_file')

        except Exception as e:
            print('❌ Invalid Avro schema: $schema_file')
            print(f'Error: {e}')
            sys.exit(1)
            "
        }

        # Validate all .avsc files
        find . -name "*.avsc" -type f | while read schema_file; do
            validate_avro_schema "$schema_file"
        done

    - name: Check schema compatibility
      run: |
        cd shared/schemas

        # Check for breaking changes (simplified check)
        echo "Checking schema compatibility..."

        # This is a placeholder for more sophisticated compatibility checking
        # In production, you'd use tools like Confluent Schema Registry or custom tools

        python3 -c "
        import json
        import os
        from pathlib import Path

        def check_schema_evolution(schema_file):
            print(f'Checking evolution rules for {schema_file}...')

            with open(schema_file, 'r') as f:
                schema = json.load(f)

            # Basic checks for good schema evolution practices
            if schema.get('type') == 'record':
                fields = schema.get('fields', [])

                for field in fields:
                    field_name = field.get('name')
                    field_type = field.get('type')

                    # Check for optional fields (good for evolution)
                    if isinstance(field_type, list) and 'null' in field_type:
                        print(f'  ✅ Optional field: {field_name}')
                    elif 'default' in field:
                        print(f'  ✅ Field with default: {field_name}')
                    else:
                        print(f'  ⚠️  Required field: {field_name}')

            return True

        # Check all record schemas
        for schema_file in Path('.').rglob('*.avsc'):
            if schema_file.is_file():
                check_schema_evolution(schema_file)
        "

    - name: Test Python type definitions
      run: |
        cd shared

        # Test that Python types can be imported
        python3 -c "
        import sys
        sys.path.append('.')

        try:
            from types import (
                AvroMetadata, AvroDevice,
                AvroBloodGlucoseRecord, AvroHeartRateRecord,
                HealthDataProcessingMessage, ETLProcessingResult
            )
            print('✅ All Python types imported successfully')

            # Test basic type creation
            metadata = AvroMetadata(
                id='test-id',
                data_origin_package_name='com.test.app',
                last_modified_time_epoch_millis=1234567890000,
                client_record_version=1
            )
            print('✅ AvroMetadata creation successful')

        except ImportError as e:
            print(f'❌ Import error: {e}')
            sys.exit(1)
        except Exception as e:
            print(f'❌ Type creation error: {e}')
            sys.exit(1)
        "

    - name: Test validation framework
      run: |
        cd shared

        # Test validation components
        python3 -c "
        import sys
        sys.path.append('.')

        try:
            from validation import (
                BloodGlucoseValidator, HeartRateValidator,
                ValidationResult, ValidationError, ValidationSeverity
            )
            print('✅ Validation framework imported successfully')

            # Test basic validation
            result = ValidationResult(
                is_valid=True,
                quality_score=1.0,
                errors=[],
                metadata={'test': 'data'}
            )
            print('✅ ValidationResult creation successful')

        except ImportError as e:
            print(f'❌ Validation import error: {e}')
            sys.exit(1)
        except Exception as e:
            print(f'❌ Validation creation error: {e}')
            sys.exit(1)
        "

    - name: Generate schema documentation
      run: |
        cd shared/schemas

        # Generate a simple schema documentation report
        python3 -c "
        import json
        from pathlib import Path

        print('# Health Data AI Platform - Schema Report')
        print('## Generated on: $(date)')
        print()

        def document_schema(schema_file):
            with open(schema_file, 'r') as f:
                schema = json.load(f)

            name = schema.get('name', 'Unknown')
            doc = schema.get('doc', 'No documentation available')
            schema_type = schema.get('type', 'unknown')

            print(f'### {name}')
            print(f'**Type:** {schema_type}')
            print(f'**File:** {schema_file}')
            print(f'**Description:** {doc}')
            print()

            if schema_type == 'record':
                fields = schema.get('fields', [])
                if fields:
                    print('**Fields:**')
                    for field in fields:
                        field_name = field.get('name')
                        field_type = field.get('type')
                        field_doc = field.get('doc', '')
                        print(f'- `{field_name}`: {field_type} - {field_doc}')
                    print()

        # Document all schemas
        for schema_file in sorted(Path('.').rglob('*.avsc')):
            if schema_file.is_file():
                document_schema(schema_file)
        " > schema-report.md

    - name: Upload schema report
      uses: actions/upload-artifact@v4
      with:
        name: schema-documentation
        path: shared/schemas/schema-report.md

    - name: Check for schema changes
      if: github.event_name == 'pull_request'
      run: |
        echo "## Schema Changes" >> $GITHUB_STEP_SUMMARY
        echo "This PR modifies the following schema files:" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        # List changed schema files
        git diff --name-only origin/main...HEAD | grep -E '\.(avsc|py) | grep -E '^shared/(schemas|types|validation)/' || echo "No schema files changed" >> $GITHUB_STEP_SUMMARY

        echo "" >> $GITHUB_STEP_SUMMARY
        echo "Please ensure:" >> $GITHUB_STEP_SUMMARY
        echo "- [ ] Schema changes are backward compatible" >> $GITHUB_STEP_SUMMARY
        echo "- [ ] Python types are updated accordingly" >> $GITHUB_STEP_SUMMARY
        echo "- [ ] Documentation is updated" >> $GITHUB_STEP_SUMMARY
        echo "- [ ] Clinical validation rules are reviewed" >> $GITHUB_STEP_SUMMARY